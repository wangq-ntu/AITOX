{
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Let's see if we can implement RAG!\n",
        "\n",
        "#### We are going to build a conversational chatbot using the OpenAI API. We will first load a pre-trained model, which references contextual documents via RAG before giving an answer."
      ],
      "metadata": {
        "id": "NfNzX-Ttv57A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azaLwuGgz7cF",
        "outputId": "66d5572b-31e6-4acf-878e-812176e2ded6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install the necessary libraries\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "!pip install faiss-gpu\n",
        "!pip install langchain_experimental\n",
        "!pip install \"langchain[docarray]\"\n",
        "!pip install -U langchain-openai"
      ],
      "metadata": {
        "id": "R-SndD3VOdE_",
        "outputId": "1f375719-d8d3-47cd-cb56-deb96c566079",
        "execution": {
          "iopub.status.busy": "2024-05-23T15:31:43.055394Z",
          "iopub.execute_input": "2024-05-23T15:31:43.055829Z",
          "iopub.status.idle": "2024-05-23T15:34:31.673976Z",
          "shell.execute_reply.started": "2024-05-23T15:31:43.055797Z",
          "shell.execute_reply": "2024-05-23T15:34:31.672785Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.6-py3-none-any.whl (975 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.10 (from langchain)\n",
            "  Downloading langchain_core-0.2.11-py3-none-any.whl (337 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.4/337.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.83-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.10->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.6 langchain-core-0.2.11 langchain-text-splitters-0.2.2 langsmith-0.1.83 orjson-3.10.6\n",
            "Collecting openai\n",
            "  Downloading openai-1.35.10-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.0)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.10\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Collecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.0.62-py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.7/202.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-community<0.3.0,>=0.2.6 (from langchain_experimental)\n",
            "  Downloading langchain_community-0.2.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.2.11)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.3.0,>=0.2.6->langchain_experimental)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (0.2.6)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (0.1.83)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (8.4.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain_experimental) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain_experimental) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain_experimental) (2.8.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.6->langchain_experimental)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.6->langchain_experimental)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain_experimental) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (0.2.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.10->langchain_experimental) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.10->langchain_experimental) (2.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.10->langchain_experimental) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.6->langchain_experimental)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community, langchain_experimental\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.6 langchain_experimental-0.0.62 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Requirement already satisfied: langchain[docarray] in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
            "\u001b[33mWARNING: langchain 0.2.6 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (0.2.11)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (0.1.83)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (2.8.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (8.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain[docarray]) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain[docarray]) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain[docarray]) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain[docarray]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain[docarray]) (2.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain[docarray]) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain[docarray]) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain[docarray]) (3.0.0)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.14-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3,>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.2.11)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.35.10)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (0.1.83)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (2.8.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (8.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain-openai) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.7)\n",
            "Installing collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.1.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary libraries\n",
        "\n",
        "# document loader for loading data from source\n",
        "from langchain.document_loaders import TextLoader\n",
        "# text splitter for chunking\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# Facebook AI similarity search, FAISS, vector store\n",
        "# efficient similarity search and clustering amongst our embeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "# allows us to work with OpenAI chat models\n",
        "from langchain_openai import ChatOpenAI\n",
        "# allows for the storing of conversational history\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "# support for follow-up questions in a RAG chain\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "# import the PyPDFLoader library for loading and splitting PDF-formatted documents\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "# module whose associated function allows us to search for files that match a specific file\n",
        "# pattern or name\n",
        "import glob\n",
        "# import the embeddings model for our vector store\n",
        "from langchain_openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "KZ-O5Zn8OgzQ",
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:31.676705Z",
          "iopub.execute_input": "2024-05-23T15:34:31.677124Z",
          "iopub.status.idle": "2024-05-23T15:34:33.689671Z",
          "shell.execute_reply.started": "2024-05-23T15:34:31.677086Z",
          "shell.execute_reply": "2024-05-23T15:34:33.688404Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the os module, read in our openAI API key\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'sk-proj-lEZcYVcnDYbUcSFaeVFYT3BlbkFJCo6RdH02kBdqbkdFCky5'"
      ],
      "metadata": {
        "id": "HL3HcZbZPaUV",
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:33.691332Z",
          "iopub.execute_input": "2024-05-23T15:34:33.692279Z",
          "iopub.status.idle": "2024-05-23T15:34:33.698349Z",
          "shell.execute_reply.started": "2024-05-23T15:34:33.692242Z",
          "shell.execute_reply": "2024-05-23T15:34:33.697205Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: DATA LOADING\n",
        "# Let's prepare our data first\n",
        "# upload the RPA files, naming the entire dataset \"rpa-docs\"\n",
        "# copy the filepath for the root directory and save it as follows\n",
        "# remember to add the forward slash at the end\n",
        "#data_root = \"/kaggle/input/rpa-docs/\"\n",
        "data_root = \"/content/drive/MyDrive/LLM_RAG/PDF/\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:33.701679Z",
          "iopub.execute_input": "2024-05-23T15:34:33.702474Z",
          "iopub.status.idle": "2024-05-23T15:34:33.718849Z",
          "shell.execute_reply.started": "2024-05-23T15:34:33.702436Z",
          "shell.execute_reply": "2024-05-23T15:34:33.717879Z"
        },
        "trusted": true,
        "id": "5B_Mu1qDv57G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in all the filenames\n",
        "filenames = glob.glob(data_root + \"*.pdf\")\n",
        "filenames"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:33.720595Z",
          "iopub.execute_input": "2024-05-23T15:34:33.720999Z",
          "iopub.status.idle": "2024-05-23T15:34:33.743819Z",
          "shell.execute_reply.started": "2024-05-23T15:34:33.720959Z",
          "shell.execute_reply": "2024-05-23T15:34:33.742716Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J51P_Uznv57G",
        "outputId": "5a067b0c-1f80-4975-bfcc-25977f7759ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/LLM_RAG/PDF/D2CP05465E.pdf',\n",
              " '/content/drive/MyDrive/LLM_RAG/PDF/1-s2.0-S0167732223001885-main.pdf',\n",
              " '/content/drive/MyDrive/LLM_RAG/PDF/ChemBioChem - 2024 - Wang - ATOMISTIC CHARACTERIZATION OF HEALTHY AND DAMAGED HAIR SURFACES  A MOLECULAR DYNAMICS STUDY OF.pdf',\n",
              " '/content/drive/MyDrive/LLM_RAG/PDF/sanders-et-al-2023-exploring-the-effects-of-wetting-and-free-fatty-acid-deposition-on-an-atomistic-hair-fiber-surface.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install pypdf for retrieve pdf data"
      ],
      "metadata": {
        "id": "bqMPMvD91uMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeIHl3mb3Ea7",
        "outputId": "9e3431c6-b810-4779-92d0-80d3267bb263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/290.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m204.8/290.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create an empty list to store the contents of the PDF files\n",
        "documents = []\n",
        "\n",
        "# cycle through each filepath\n",
        "for file in filenames:\n",
        "    # create a PyPDFLoader object for the current file\n",
        "    loader = PyPDFLoader(file)\n",
        "    # make use of the load() method to load in the contents of the file\n",
        "    document = loader.load()\n",
        "    # add the contents to our list\n",
        "    documents += document"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:33.745279Z",
          "iopub.execute_input": "2024-05-23T15:34:33.745831Z",
          "iopub.status.idle": "2024-05-23T15:34:37.225652Z",
          "shell.execute_reply.started": "2024-05-23T15:34:33.745798Z",
          "shell.execute_reply": "2024-05-23T15:34:37.224438Z"
        },
        "trusted": true,
        "id": "asHnKAtZv57G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the size of our list\n",
        "# we have 11, i.e. the contents of each page is extracted as an element in the list\n",
        "# we can check for ourselves what's the total page count across the four files\n",
        "len(documents) # Number of pages"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:37.227437Z",
          "iopub.execute_input": "2024-05-23T15:34:37.228471Z",
          "iopub.status.idle": "2024-05-23T15:34:37.235497Z",
          "shell.execute_reply.started": "2024-05-23T15:34:37.228430Z",
          "shell.execute_reply": "2024-05-23T15:34:37.234102Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdVWCEebv57H",
        "outputId": "1acdf992-65e2-4f49-fdcd-5d6399328404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the result by accessing the contents of the first file\n",
        "documents[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:37.236949Z",
          "iopub.execute_input": "2024-05-23T15:34:37.237274Z",
          "iopub.status.idle": "2024-05-23T15:34:37.250332Z",
          "shell.execute_reply.started": "2024-05-23T15:34:37.237245Z",
          "shell.execute_reply": "2024-05-23T15:34:37.249068Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "438JFC3uv57H",
        "outputId": "44fd4097-2053-4fc8-e5ec-2f4327eb2ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/drive/MyDrive/LLM_RAG/PDF/D2CP05465E.pdf', 'page': 0}, page_content='1768 |  Phys. Chem. Chem. Phys., 2023, 25, 1768–1780 This journal is © the Owner Societies 2023\\nCite this: Phys. Chem. Chem. Phys.,\\n2023, 25, 1768Shearing friction behaviour of synthetic polymers\\ncompared to a functionalized polysaccharide onbiomimetic surfaces: models for the prediction\\nof performance of eco-designed formulations †\\nBenjamin J. Coscia,\\naJohn C. Shelley,\\naAndrea R. Browning,a\\nJeﬀrey M. Sanders,\\nbRobin Chaudret,cRoger Rozot,\\ndFabien Le ´onforte,\\n *d\\nMathew D. Halls\\neand Gustavo S. Luengo\\n *d\\nThe substitution of natural, bio-based and/or biodegradable polymers for those of petrochemical origin\\nin consumer formulations has become an active area of research and development as the sourcing anddestiny of material components becomes a more critical factor in product design. These polymers oftendiﬀer from their petroleum-based counterparts in topology, raw material composition and solutionbehaviour. Eﬀective and eﬃcient reformulation that maintains comparable cosmetic performance to\\nexisting products requires a deep understanding of the diﬀerences in frictional behaviour between\\npolymers as a function of their molecular structure. In this work, we simulate the tribological behaviourof three topologically distinct polymers in solution with surfactants and in contact with hair-biomimeticpatterned surfaces. We compare a generic functionalized polysaccharide to two performant polymersused in shampoo formulations: a strongly positively charged polyelectrolyte and a zwitterioniccopolymer. Topological diﬀerences are expected to aﬀect rheological properties, as well as their directinteraction with structured biological substrates. Using a refined Martini-style coarse-grained model wedescribe the polymer-dependent diﬀerences in aggregation behaviour as well as selective interactions\\nwith a biomimetic model hair surface. Additionally, we introduce a formalism to characterize the\\nresponse of the solution to shear as an initial study on lubrication properties, which define the sensorialperformance of these systems in cosmetics ( i.e., manageability, touch, etc.). The tools and techniques\\npresented in this work illustrate the strength of molecular simulation in eco-design of formulation as acomplement to experiment. These eﬀorts help advance our understanding of how we can relatecomplex atomic-scale solution behaviour to relevant macroscopic properties. We expect thesetechniques to play an increasingly important role in advancing strategies for green polymer formulationdesign by providing an understanding for how new polymers could reach and even exceed the level of\\nperformance of existing polymers.\\n1. Introduction\\nThe future of sustainable cosmetic formulation development\\nrelies on a holistic approach to ingredient design and produc-tion which accounts for the environmental impacts of theirwhole lifecycle. In choosing ingredients, we must be vigilant ofthe sources of raw materials, ensuring fair trade practices thatlead to positive societal impacts.\\n1Additionally, we must adhere\\nto the principles of green chemistry which emphasize the useof renewable raw materials, safe, low-energy and low-wasteprocesses, and minimal environmental and human healthimpacts.\\n2\\nAt present, there is a well-established set of petrochemical-\\nderived ingredients that are trusted to achieve the performance\\nrequired by formulations used for washing and conditioning in\\nthe cosmetic and textile industries. For example, widely usedcationic polymers and surfactants are very often of petrochem-ical origin.\\n3,4Due to the substantial quantity of these chemicals\\nthat are being used on an ongoing basis, they ultimately end upmeasurably accumulating in the environment.\\n5aSchro¨dinger, Inc., Portland, OR 97204, USA\\nbSchro¨dinger, Inc., New York, NY 10036, USA\\ncSchro¨dinger, Inc., 80538 Mu ¨nchen, Germany\\ndL’Ore´al Research and Innovation, Aulnay-Sous Bois, France.\\nE-mail: gluengo@rd.loreal.com, fabien.leonforte@loreal.com\\neSchro¨dinger, Inc., San Diego, California 92121, USA\\n†Electronic supplementary information (ESI) available. See DOI: https://doi.org/\\n10.1039/d2cp05465eReceived 22nd November 2022,\\nAccepted 19th December 2022\\nDOI: 10.1039/d2cp05465e\\nrsc.li/pccpPCCP\\nPAPER\\nOpen Access Article. Published on 22 December 2022. Downloaded on 4/26/2024 1:55:27 AM. \\n This article is licensed under a \\nCreative Commons Attribution-NonCommercial 3.0 Unported Licence.\\nView Article Online\\nView Journal\\n | View Issue')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: CHUNKING\n",
        "# now that we have loaded in the external data store, we chunk the documents\n",
        "# the purpose of chunking is that the documents, in their original states, are too long\n",
        "# to fit into the LLM's context window, so we need to chunk them into smaller pieces\n",
        "# LangChain comes with many text splitters for this purpose\n",
        "\n",
        "# create our text splitter object, specifying that we will be chunking into bits that are\n",
        "# 512 characters in size, with an overlap of 100 characters between chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 512, chunk_overlap = 100,)  ## optimize chunk_size\n",
        "\n",
        "# apply the text splitter object to our documents, chunking them according to the parameters\n",
        "# previously specified using the split_documents() method\n",
        "data = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:37.251896Z",
          "iopub.execute_input": "2024-05-23T15:34:37.252710Z",
          "iopub.status.idle": "2024-05-23T15:34:37.265145Z",
          "shell.execute_reply.started": "2024-05-23T15:34:37.252668Z",
          "shell.execute_reply": "2024-05-23T15:34:37.263853Z"
        },
        "trusted": true,
        "id": "6x441pi8v57I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check the length to see the number of chunks that has resulted\n",
        "len(data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:37.271700Z",
          "iopub.execute_input": "2024-05-23T15:34:37.272136Z",
          "iopub.status.idle": "2024-05-23T15:34:37.280186Z",
          "shell.execute_reply.started": "2024-05-23T15:34:37.272104Z",
          "shell.execute_reply": "2024-05-23T15:34:37.279213Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFQguLhjv57I",
        "outputId": "38fad557-b89c-4c79-93ec-832dd6cd67f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "689"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the result of the first chunk\n",
        "data[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:37.281288Z",
          "iopub.execute_input": "2024-05-23T15:34:37.281896Z",
          "iopub.status.idle": "2024-05-23T15:34:37.295695Z",
          "shell.execute_reply.started": "2024-05-23T15:34:37.281863Z",
          "shell.execute_reply": "2024-05-23T15:34:37.294693Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUM4Z88ev57I",
        "outputId": "d7254c4d-4902-4442-8ac1-7d3dd9cc7d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/drive/MyDrive/LLM_RAG/PDF/D2CP05465E.pdf', 'page': 0}, page_content='1768 |  Phys. Chem. Chem. Phys., 2023, 25, 1768–1780 This journal is © the Owner Societies 2023\\nCite this: Phys. Chem. Chem. Phys.,\\n2023, 25, 1768Shearing friction behaviour of synthetic polymers\\ncompared to a functionalized polysaccharide onbiomimetic surfaces: models for the prediction\\nof performance of eco-designed formulations †\\nBenjamin J. Coscia,\\naJohn C. Shelley,\\naAndrea R. Browning,a\\nJeﬀrey M. Sanders,\\nbRobin Chaudret,cRoger Rozot,\\ndFabien Le ´onforte,\\n *d\\nMathew D. Halls\\neand Gustavo S. Luengo\\n *d')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: STORING\n",
        "# after chunking, to enable semantic search across the text chunks, we need to generate the vector\n",
        "# embeddings for each chunk, and then store these embeddings\n",
        "\n",
        "# here we define our embeddings model, to generate the embeddings\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:37.296808Z",
          "iopub.execute_input": "2024-05-23T15:34:37.297769Z",
          "iopub.status.idle": "2024-05-23T15:34:37.337578Z",
          "shell.execute_reply.started": "2024-05-23T15:34:37.297735Z",
          "shell.execute_reply": "2024-05-23T15:34:37.336162Z"
        },
        "trusted": true,
        "id": "zzoSYLPLv57J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert our chunked documents into vector embeddings, and load the embeddings into the\n",
        "# FAISS vector store\n",
        "vectorstore = FAISS.from_documents(data, embedding = embeddings)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:37.339634Z",
          "iopub.execute_input": "2024-05-23T15:34:37.340104Z",
          "iopub.status.idle": "2024-05-23T15:34:41.135029Z",
          "shell.execute_reply.started": "2024-05-23T15:34:37.340070Z",
          "shell.execute_reply": "2024-05-23T15:34:41.133827Z"
        },
        "trusted": true,
        "id": "uyMro4NUv57J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: DOCUMENT RETRIEVAL\n",
        "# run the code below to use our vector store as a retriever\n",
        "# this enables us to fetch additional context based on the semantic similarity between user query\n",
        "# and the chunk embeddings\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:41.136628Z",
          "iopub.execute_input": "2024-05-23T15:34:41.137060Z",
          "iopub.status.idle": "2024-05-23T15:34:41.142639Z",
          "shell.execute_reply.started": "2024-05-23T15:34:41.137028Z",
          "shell.execute_reply": "2024-05-23T15:34:41.141106Z"
        },
        "trusted": true,
        "id": "NiELOpnHv57J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the ChatPromptTemplate class, allowing us to create flexible templated prompts\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# to augment the question from the user with the additional context (to form our augmented prompt),\n",
        "# we need to prepare a prompt template; the template can readily be customisable as shown\n",
        "# by the following lines of code\n",
        "\n",
        "# here, we specify the template such that a combination of both the context from our vector store\n",
        "# and the existing knowledge base of the model can be used to answer the question\n",
        "# rather than just one or the other\n",
        "template = \"\"\"You are a scientist for question-answering tasks.\n",
        "Use the following pieces of retrieved context to answer the question.\n",
        "If the context is not relevant,please answer the question by using your own knowledge about the topic\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "# load in our template above to create our templated prompt\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "print(prompt)\n",
        "\n",
        "# Here the input to the prompt we specified above is expected to be a map with\n",
        "# keys “context” and “question”"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:41.144233Z",
          "iopub.execute_input": "2024-05-23T15:34:41.144700Z",
          "iopub.status.idle": "2024-05-23T15:34:41.161442Z",
          "shell.execute_reply.started": "2024-05-23T15:34:41.144668Z",
          "shell.execute_reply": "2024-05-23T15:34:41.160236Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r74V64zv57K",
        "outputId": "6c13bc9e-f0f5-4168-90dc-72d045b0fb91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['context', 'question'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='You are a scientist for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question.\\nIf the context is not relevant,please answer the question by using your own knowledge about the topic\\n\\nContext: {context}\\n\\nQuestion: {question}\\n'))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the class that allows us to pass on the user's input to the model unchanged\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "# converts the output from our LLM into a string format\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "# specify our LLM using the ChatOpenAI class we imported earlier\n",
        "# gpt-3.5-turbo is more cost efficient than gpt-4\n",
        "# setting temperature = 0 results in more deterministic responses\n",
        "# we can fiddle around with this parameter (from 0 to 2) to experiment with the responses we get\n",
        "# an alternative (commented out) has been included for our experimentation\n",
        "llm = ChatOpenAI(model_name = \"gpt-3.5-turbo\", temperature = 0)\n",
        "# llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.7, )\n",
        "\n",
        "# now we can build a chain for the RAG pipeline, chaining together the retriever, the prompt template\n",
        "# and the LLM\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# as mentioned above, the input to the prompt we specified earlier is expected to be a map with\n",
        "# keys “context” and “question”\n",
        "# \"question\" is just the user input; thus we just need to get the context using our retriever and\n",
        "# passthrough the user input under the “question” key\n",
        "# In this case, RunnablePassthrough() allows us to pass on the user’s question to the prompt\n",
        "\n",
        "# once our RAG chain is defined, we can invoke it\n",
        "# here, the vector store will be queried by the user prompt and the most relevant\n",
        "# data will be retrieved to augment the prompt, and used to call the model\n",
        "# the model will now respond based on the augmented prompt\n",
        "query = \"Is the contribution of Coulombic interaction energies larger than LJ in total energy between FMEA and protein?\"\n",
        "rag_chain.invoke(query)\n",
        "\n",
        "# you can see that the response is taken within context; check with the document\n",
        "# \"RPA-Developer-Foundation-Training.pdf\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:41.162578Z",
          "iopub.execute_input": "2024-05-23T15:34:41.163812Z",
          "iopub.status.idle": "2024-05-23T15:34:42.929413Z",
          "shell.execute_reply.started": "2024-05-23T15:34:41.163773Z",
          "shell.execute_reply": "2024-05-23T15:34:42.928052Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "CJksp3V3v57L",
        "outputId": "aba257cd-3328-4788-f43b-ca23b510a411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, the contribution of Coulombic interaction energies is larger than LJ in total energy between FMEA and protein. This is mainly due to the proximity of the polar head group with the amino acids on the protein surface.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is the Thickness of FMEA in Wet condition\"\n",
        "rag_chain.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "FPji3e3X2iEn",
        "outputId": "5ab74b47-2fad-47be-a159-35b6e907cbb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The thickness of FMEA in wet condition is visibly larger compared to dry condition, as the fatty acid layers take on an extended conformation to repel water. The transition from thicker (~3nm) to thinner (~1nm) fatty acid layers is demonstrated with the depletion of FMEA, which influences the water penetration.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "re-ranking of the retrieval results"
      ],
      "metadata": {
        "id": "sYRYfFMM26Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's contrast the results when we introduce re-ranking of the retrieval results from the vector store\n",
        "# here, we specify that we will use the MMR re-ranking algorithm\n",
        "# the top three results will be retrieved (k = 3)\n",
        "# and we set a diversity factor, lambda_mult, whose values range between 0 and 1\n",
        "# where 0 is maximum diversity and 1 is minimum diversity\n",
        "# here, we set lambda_mult = 0.1 for a relatively high degree of diversity in the results\n",
        "\n",
        "retriever = vectorstore.as_retriever(\n",
        "search_type = 'mmr',  # re-ranking algorithm\n",
        "search_kwargs = {'k':3, 'lamba_mult': 0.1})\n",
        "\n",
        "# rebuild the RAG chain with the redefined retriever, and invoke it to answer our query\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# checking against the source PDF, we see that the answer provided is not the most direct\n",
        "# one as given in the source\n",
        "query = \"Is the contribution of Coulombic interaction energies larger than LJ in total energy between FMEA and protein?\"\n",
        "rag_chain.invoke(query)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:42.931113Z",
          "iopub.execute_input": "2024-05-23T15:34:42.931601Z",
          "iopub.status.idle": "2024-05-23T15:34:44.229218Z",
          "shell.execute_reply.started": "2024-05-23T15:34:42.931568Z",
          "shell.execute_reply": "2024-05-23T15:34:44.227969Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "fjmqB0dtv57L",
        "outputId": "21f5774a-06f2-4ab1-caf1-2aa791b5d858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, according to the retrieved context, the contribution of Coulombic interaction energies is larger than LJ in total energy between FMEA and protein surfaces. This is mainly due to the proximity of the polar head group with the amino acids on the protein surface.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the model can also answer out of context questions\n",
        "# here, because there's no relevant result from the vector store\n",
        "# the original prompt will be used to call the model directly\n",
        "# from which the response will be given based on the existing knowledge base of the model\n",
        "query = \"Who won the Chemistry Nobel prize in 2009?\"\n",
        "rag_chain.invoke(query)\n",
        "\n",
        "# Let's return to our slides"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:34:44.231082Z",
          "iopub.execute_input": "2024-05-23T15:34:44.231533Z",
          "iopub.status.idle": "2024-05-23T15:34:46.066785Z",
          "shell.execute_reply.started": "2024-05-23T15:34:44.231493Z",
          "shell.execute_reply": "2024-05-23T15:34:46.065506Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "dAXouy8bv57M",
        "outputId": "f1a12115-5714-4acc-dd7f-953863b8b1e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Chemistry Nobel Prize in 2009 was awarded to Venkatraman Ramakrishnan, Thomas A. Steitz, and Ada E. Yonath for their studies on the structure and function of the ribosome.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acknowledgements: This notebook was adapted from the following sources:\n",
        "\n",
        "https://scalexi.medium.com/implementing-a-retrieval-augmented-generation-rag-system-with-openais-api-using-langchain-ab39b60b4d9f\n",
        "\n",
        "https://towardsdatascience.com/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2"
      ],
      "metadata": {
        "id": "ND2cXASFv57M"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ILSM3G1v57M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}